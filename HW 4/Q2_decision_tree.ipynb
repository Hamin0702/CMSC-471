{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGu5vjbDEI5Ybzjoti89hn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"pFzFprx1LAwz","executionInfo":{"status":"ok","timestamp":1670023846105,"user_tz":300,"elapsed":1832,"user":{"displayName":"Hamin Han","userId":"16015672543135784716"}}},"outputs":[],"source":["import pandas as pd\n","from scipy.stats import entropy as ent\n","import numpy as np"]},{"cell_type":"code","source":["## To Do: Write the entropy(label) function\n","## Should find the information entropy of dataset (T) with class \"label\" i.e. Info(T)\n","def entropy(dataset, label):\n","    label_list = dataset[label].tolist()\n","    value,counts = np.unique(label_list, return_counts=True)\n","    return ent(counts, base=2)"],"metadata":{"id":"sG7IWDvcLJ-M","executionInfo":{"status":"ok","timestamp":1670023847176,"user_tz":300,"elapsed":188,"user":{"displayName":"Hamin Han","userId":"16015672543135784716"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["## To Do: Write the information_gain(feature, label) function\n","## Should find the information gain of \"feature\"(X) on dataset (T) with class \"label\" i.e. Gain(X,T)\n","def information_gain(dataset, feature, label):\n","\n","    # Calculate original entropy on the target column\n","    original_entropy = entropy(dataset, label)\n","\n","    # Find unque values in the split column\n","    values = dataset[feature].unique()\n","\n","    # Make two subsets of the data, based on the unique values\n","    left_split = dataset[dataset[feature] == values[0]]\n","    right_split = dataset[dataset[feature] == values[1]]\n","\n","    # Loop through the splits and calculate the subset entropies\n","    to_subtract = 0\n","    for subset in [left_split, right_split]:\n","        prob = (subset.shape[0] / dataset.shape[0]) \n","        to_subtract += prob * entropy(subset,label)\n","    \n","    # Return information gain\n","    return original_entropy - to_subtract"],"metadata":{"id":"TfvnxMxqLMe2","executionInfo":{"status":"ok","timestamp":1670023848633,"user_tz":300,"elapsed":205,"user":{"displayName":"Hamin Han","userId":"16015672543135784716"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["## To Do: Fill split(dataset, feature) function\n","## Should split the dataset on a feature\n","## Implementing a little differently, returns a dictionary with the information gains\n","def split(dataset, label):\n","    columns = [\"COLOR\", \"SIZE\", \"ACT\", \"AGE\"]\n","\n","    #Intialize an empty dictionary for information gains\n","    information_gains = {}\n","\n","    #Iterate through each column name in our list\n","    for col in columns:\n","        #Find the information gain for the column\n","        info_gain = information_gain(dataset, col, label)\n","        #Add the information gain to our dictionary using the column name as the ekey                                         \n","        information_gains[col] = info_gain\n","\n","    #return the dictionary\n","    return information_gains"],"metadata":{"id":"FAKHp0lFLOS2","executionInfo":{"status":"ok","timestamp":1670023850554,"user_tz":300,"elapsed":155,"user":{"displayName":"Hamin Han","userId":"16015672543135784716"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["## To Do: Fill find_best_split(dataset, label) function\n","## Should find the best feature to split the dataset on\n","## Should return best_feature, best_gain\n","def find_best_split(dataset, label):\n","    ## TO DO: Find the best feature to split the dataset\n","    info_gains = split(dataset,label)\n","    \n","    # Get the best fature/value\n","    best_feature = max(info_gains, key=info_gains.get)\n","    best_gain = info_gains[best_feature]\n","    return best_feature, best_gain"],"metadata":{"id":"LRvXQ1veLP0N","executionInfo":{"status":"ok","timestamp":1670023852450,"user_tz":300,"elapsed":199,"user":{"displayName":"Hamin Han","userId":"16015672543135784716"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Press the green button in the gutter to run the script.\n","if __name__ == '__main__':\n","    data = pd.read_csv('balloons.csv')\n","\n","    best_feature, best_gain = find_best_split(data, \"INFLATED\")\n","    f = open(\"output_balloons.txt\", \"w\")\n","    f.write(\"The Best Feature is {} with a Gain of : {}\".format(best_feature, best_gain))\n","    f.close()"],"metadata":{"id":"g9gmemNHLRM4","executionInfo":{"status":"ok","timestamp":1670023854572,"user_tz":300,"elapsed":139,"user":{"displayName":"Hamin Han","userId":"16015672543135784716"}}},"execution_count":6,"outputs":[]}]}